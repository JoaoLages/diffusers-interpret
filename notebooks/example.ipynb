{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb135c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.057273149490356445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 12506,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de51421b1a91410a93418d690354baf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.047919273376464844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 543,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de32a462673e4b0ea4921de00faafb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/543 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.037320613861083984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 4628,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6577a2cd0a4425d99096ac0b6347093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.07503557205200195,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 608098599,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf5cf7b960d4a4997f3a86567d8fdd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/608M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# make sure you're logged in with `huggingface-cli login`\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler\n",
    "from contextlib import nullcontext\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lms = LMSDiscreteScheduler(\n",
    "    beta_start=0.00085, \n",
    "    beta_end=0.012, \n",
    "    beta_schedule=\"scaled_linear\"\n",
    ")\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\", \n",
    "    scheduler=lms,\n",
    "    revision='fp16',\n",
    "    torch_dtype=torch.float16,\n",
    "    use_auth_token=\"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\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools \n",
    "\n",
    "\n",
    "class DummyInputIds:\n",
    "    def __init__(self, input_ids):\n",
    "        self.input_ids = input_ids\n",
    "\n",
    "    def to(self, device: str):\n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.input_ids.shape[:-1] # cuts last dimension\n",
    "        \n",
    "\n",
    "def tokenizer_prefix_function(function):\n",
    "\n",
    "    class DummyReturnClass:\n",
    "        def __init__(self, input_ids):\n",
    "            self.input_ids = DummyInputIds(input_ids)\n",
    "            \n",
    "    @functools.wraps(function)\n",
    "    def run(*args, **kwargs):\n",
    "        if 'text' in kwargs and isinstance(kwargs['text'], list) and isinstance(kwargs['text'][0], torch.Tensor):\n",
    "            return DummyReturnClass(input_ids=kwargs['text'][0])\n",
    "        elif len(args) > 0 and isinstance(args[0], list) and isinstance(args[0][0], torch.Tensor):\n",
    "            return DummyReturnClass(input_ids=args[0][0])\n",
    "        # TODO: do for list of strings\n",
    "        else:\n",
    "            return function(*args, **kwargs)\n",
    "    return run\n",
    "\n",
    "\n",
    "def patch_call(instance, func):\n",
    "    class _(type(instance)):\n",
    "        def __call__(self, *arg, **kwarg):\n",
    "            return func(*arg, **kwarg)\n",
    "    instance.__class__ = _\n",
    "\n",
    "patch_call(pipe.tokenizer, tokenizer_prefix_function(pipe.tokenizer.__call__))\n",
    "pipe.tokenizer.tokenize = tokenizer_prefix_function(pipe.tokenizer.tokenize)\n",
    "pipe.tokenizer.encode = tokenizer_prefix_function(pipe.tokenizer.encode)\n",
    "pipe.tokenizer.encode_plus = tokenizer_prefix_function(pipe.tokenizer.encode_plus)\n",
    "pipe.tokenizer.batch_encode_plus = tokenizer_prefix_function(pipe.tokenizer.batch_encode_plus)\n",
    "\n",
    "\n",
    "def text_encoder_prefix_function(function):\n",
    "    @functools.wraps(function)\n",
    "    def run(*args, **kwargs):\n",
    "        \n",
    "        if 'input_ids' in kwargs:\n",
    "            x = kwargs['input_ids']\n",
    "        else:\n",
    "            x = args[0]\n",
    "            \n",
    "        return function(*args, **kwargs) if not isinstance(x, DummyInputIds) else [x.input_ids]\n",
    "    return run\n",
    "\n",
    "patch_call(pipe.text_encoder, text_encoder_prefix_function(pipe.text_encoder.__call__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff3b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import (\n",
    "    IntegratedGradients,\n",
    "    Saliency,\n",
    "    InputXGradient,\n",
    "    DeepLift,\n",
    "    DeepLiftShap,\n",
    "    GuidedBackprop,\n",
    "    GuidedGradCam,\n",
    "    Deconvolution,\n",
    "    LRP\n",
    ")\n",
    "from typing import Optional \n",
    "\n",
    "def forward(\n",
    "    input_embeds: torch.Tensor,\n",
    "    pipe: StableDiffusionPipeline\n",
    "):\n",
    "    return pipe([input_embeds], num_inference_steps=2, output_type=None)\n",
    "\n",
    "saliency = InputXGradient(functools.partial(forward, pipe=pipe))\n",
    "\n",
    "# get prompt text embeddings\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "text_input = pipe.tokenizer(\n",
    "    prompt,\n",
    "    padding=\"max_length\",\n",
    "    max_length=pipe.tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "text_embeddings = pipe.text_encoder(text_input.input_ids.to(pipe.device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89fe26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9812362",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = forward(text_embeddings, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a76648",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['sample'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f397cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = output['sample'].detach().numpy()\n",
    "images = (images * 255).round().astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ac01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46187146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux = saliency.attribute(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191214e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "\n",
    "with torch.autocast('cuda') if device == 'cuda' else nullcontext():\n",
    "    result = pipe(prompt, num_inference_steps=5)\n",
    "    image = result[\"sample\"][0]  \n",
    "    \n",
    "#image.save(\"astronaut_rides_horse.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9582f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db834c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59006700",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
